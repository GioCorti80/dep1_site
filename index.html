<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Black Background with White Text</title>
    <style>
        body {
            background-color: black;
            color: white;
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
        }
            /* Change hyperlink color to yellow */
            a {
                color: yellow;
            }
    </style>
</head>
<p>Could you also kindly provide us with the alias to write to the network folder \fdsfs\gfdgdf?</p>

<p>import pandas as pd

    # Sample DataFrame
    data = {'numbers': ['123456', '123456789012345678', '123456789012']}
    df = pd.DataFrame(data)
    
    # Normalize to 12 digits: Pad with zeros if <12 digits, truncate if >12 digits
    df['normalized'] = df['numbers'].apply(lambda x: str(x).zfill(12)[:12])
    
    print(df)
    </p>

<p>pd.set_option('display.max_columns', None)</p>

<p># Rename specific columns using a dictionary
    df_renamed = df.rename(columns={'col1': 'new_col_a', 'col3': 'new_col_c'})
    print("\nDataFrame after renaming specific columns:")
    print(df_renamed)</p>

<pre>from pyspark.sql import SparkSession

    # Create Spark Session with increased memory
    spark = SparkSession.builder \
        .appName("Avoid Heap Memory Error") \
        .config("spark.driver.memory", "4g") \  # Increase driver memory
        .config("spark.executor.memory", "4g") \  # Increase executor memory
        .config("spark.executor.memoryOverhead", "1g") \  # Additional overhead memory
        .config("spark.sql.shuffle.partitions", "200") \  # Reduce shuffle partitions if needed
        .getOrCreate()
    </pre>

    <p>We’ll have the information only after the CR is completed.</p>

<pre>import importlib
import your_package  # Import the package initially

# Reload the package
importlib.reload(your_package)
</pre>
<pre>
# Rename specific columns
df = df.rename(columns={'old_name1': 'new_name1', 'old_name2': 'new_name2'})
</pre>
<pre></pre>
Hi Janani,  
Roberto sent me the updated **report_mandatory.xlsx** file on Friday for the upcoming release.  
I've prepared this PR to update the **report_mandatory.xlsx** file.
</pre>

<pre>Hi Sangram,  
    Yes, I encountered a problem with the SDLC for **report-python**, but I think it's now resolved.  
    However, I'm still facing the same issue with a few SDLC controls for **report-engine**.</pre>

<pre>Okay, thanks. Now the change can be merged with the existing changes in the PRD branch.</pre>

<pre>Okay Janani,
    I've updated the Confluence page with PR 585.
    I'll inform Surendhar that he can proceed with the approval.</pre>

<pre>Hi Surendhar,
    I’ve merged my changes with Janani's in the production PR 585 for reporting-engine, which is now ready for approval.
    
    I’ve also submitted the following PRs for production for this week’s release:
    
    transaction monitoring
    
    report-python
    
    composer</pre>
<pre>prova di upload dei dati</pre>

<a href="utils/spark.html">Spark Tips</a>
<br>
<a href="utils/bq.html">bq Tips</a>
<br>
<a href="utils/bigframes.html">bigframes Tips</a>
<br>
<a href="utils/github.html">github Tips</a>
<br>
<a href="utils/pandas.html">Pandas Tips</a>