<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Black Background with White Text</title>
    <style>
        body {
            background-color: black;
            color: white;
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
        }
    </style>
</head>
<h1>python Tips</h1>
<h3>Config</h3>
<pre>
list1 = ['a', 'b', 'c', 'd']
list2 = ['b', 'x', 'a', 'z', 'c']

filtered_list2 = [item in list1]
filtered_list2 = [item for item in list2 if item in list1]

print(filtered_list2)

</pre>
<pre>
from google.cloud.logging_v2.services.logging_service_v2 import LoggingServiceV2Client

</pre>
<pre>
from datetime import datetime, timedelta

project_id = "your-gcp-project-id"
log_filter = 'resource.type="cloud_function" AND severity>=ERROR'

# Example: Last 24 hours
start = datetime.utcnow() - timedelta(days=1)
end = datetime.utcnow()

logs = read_logs(project_id, log_filter, start, end)

for entry in logs:
    print(f"{entry.timestamp} - {entry.severity} - {entry.text_payload or entry.json_payload}")

</pre>
<pre>
import holidays
from datetime import date, datetime

def is_working_day(input_date=None, country='US'):
    """
    Checks if a given date (or today if not provided) is a working day.
    Excludes weekends and public holidays.

    Args:
        input_date (str or datetime.date or datetime.datetime, optional): 
            The date to check. If None, uses today. 
            If string, format should be 'YYYY-MM-DD'.
        country (str): Country code for holidays (default 'US').

    Returns:
        bool: True if it's a working day, False otherwise.
    """
    if input_date is None:
        check_date = date.today()
    elif isinstance(input_date, str):
        check_date = datetime.strptime(input_date, "%Y-%m-%d").date()
    elif isinstance(input_date, (date, datetime)):
        check_date = input_date.date() if isinstance(input_date, datetime) else input_date
    else:
        raise ValueError("Invalid date format. Use None, a 'YYYY-MM-DD' string, or a date object.")
    
    holiday_dates = holidays.country_holidays(country)
    
    return check_date.weekday() < 5 and check_date not in holiday_dates

</pre>
<pre>
df_with_new_date = df.withColumn("new_date", add_months(df["start_date"], 3))
</pre>
<pre>
import sys
print(f"Python version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}")
print("PySpark version:", spark.version)
</pre>
<pre>
import pandas as pd
import io
import sys

# Create a sample DataFrame
data = {
    'col1': [1, 2, 3, 4, 5],
    'col2': ['A', 'B', 'C', 'D', 'E'],
    'col3': [10.1, 20.2, None, 40.4, 50.5],
    'col4': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'])
}
df = pd.DataFrame(data)

# Specify the filename for the output
output_filename = "df_info_output.txt"

# Create a string buffer to capture the output
buffer = io.StringIO()

# Redirect stdout to the buffer
sys.stdout = buffer

# Call df.info() - its output will now go to the buffer
df.info()

# Restore stdout to its original state (the console)
sys.stdout = sys.__stdout__

# Get the captured output from the buffer
captured_output = buffer.getvalue()

# Write the captured output to a text file
with open(output_filename, 'w') as f:
    f.write(captured_output)

print(f"df.info() output saved to '{output_filename}'")

# You can also print the captured output to verify
# print("\n--- Captured Output ---")
# print(captured_output)
</pre>
<pre>
from datetime import datetime

filename = f"file_strs_{datetime.now().strftime('%Y_%m')}.ok"
print(filename)
</pre>
<pre>
from google.cloud import bigquery

# Initialize BigQuery client
client = bigquery.Client()

# Define your table in the format: project.dataset.table
table_id = "your-project.your_dataset.your_table"

# Get the table metadata
table = client.get_table(table_id)

# Get the last modified time (returns timestamp in milliseconds)
last_modified_time = table.modified  # This is a datetime.datetime object

print(f"Last modified time: {last_modified_time}")
</pre>
<pre>
from google.cloud import storage
from datetime import datetime

def get_latest_file_from_gcs(bucket_name, folder='', prefix='', extension=''):
    """
    Returns the latest file in a GCS bucket directory based on last modified time.

    Parameters:
    - bucket_name (str): Name of the GCS bucket.
    - folder (str): Folder path inside the bucket ('' means root). Should not start with '/'.
    - prefix (str): Prefix of the file name.
    - extension (str): File extension to filter (e.g. '.csv', '.json').

    Returns:
    - str: Full GCS path of the latest file (gs://bucket_name/path/to/file).
    """
    client = storage.Client()
    bucket = client.bucket(bucket_name)

    # Normalize folder path
    folder_prefix = folder.strip('/')
    full_prefix = f"{folder_prefix}/{prefix}".lstrip('/') if folder_prefix else prefix

    blobs = client.list_blobs(bucket_name, prefix=full_prefix)

    # Filter by extension and track latest blob
    latest_blob = None
    for blob in blobs:
        if extension and not blob.name.endswith(extension):
            continue
        if latest_blob is None or blob.updated > latest_blob.updated:
            latest_blob = blob

    if latest_blob:
        return f"gs://{bucket_name}/{latest_blob.name}"
    else:
        return None

</pre>
<pre>
import re

text = """
Some SQL or text that mentions pwcc_dqm.tab1, pwcc_dqm.tab2, and maybe pwcc_dqm.tab3
even inside longer strings or comments like 'select * from pwcc_dqm.tab4'.
"""

# Regular expression to match pwcc_dqm.<table_name>
matches = re.findall(r'\bpwcc_dqm\.\w+\b', text)

</pre>
<pre>
from google.cloud import bigquery
from google.api_core.exceptions import NotFound

# Initialize client
client = bigquery.Client()

# Define table ID: 'project.dataset.table'
table_id = "your-project.your_dataset.your_table"

try:
    client.get_table(table_id)  # API request
    print(f"✅ Table {table_id} exists.")
    table_exists = True
except NotFound:
    print(f"❌ Table {table_id} does not exist.")
    table_exists = False

bool_value = value.lower() == "true"
</pre>
<pre>
from datetime import datetime

# Get today's date
now = datetime.now()

# Format the date strings
date_str = now.strftime("%Y%m%d")
datetime_str = now.strftime("%Y%m%d%H%M%S")

# Build the filename
filename = f"125479-4_Log_auditing_{date_str}_{datetime_str}.csv"

print(filename)

</pre>
<pre>
import subprocess

result = subprocess.run(["ls", "-l"], capture_output=True, text=True)
print(result.stdout)

</pre>
<pre>
import requests
from requests.exceptions import RequestException
import os

def check_api_connection(api_url):
    """
    Checks if a public API endpoint is reachable using a HEAD request.

    :param api_url: The full URL of the public API endpoint to check.
    :return: True if the connection is successful, False otherwise.
    """
    # No headers are needed for public APIs that don't require authentication.
    print(f"Attempting to connect to: {api_url}")
    print("-" * 30)

    try:
        # Use requests.head() to send a HEAD request.
        # The timeout parameter prevents the script from hanging indefinitely.
        response = requests.head(api_url, timeout=5)

        # A status code in the 200 range (2xx) indicates success.
        if response.status_code >= 200 and response.status_code < 300:
            print("✅ Connection successful!")
            print(f"Status Code: {response.status_code}")
            return True
        else:
            print(f"❌ Connection failed. Status Code: {response.status_code}")
            # The 'reason' provides a human-readable explanation of the status code
            print(f"Reason: {response.reason}")
            return False

    except RequestException as e:
        # This catches any network-related errors (e.g., DNS failure, connection refused).
        print(f"❌ An error occurred: {e}")
        return False

# --- Main part of the script ---
if __name__ == "__main__":
    # This is a public API endpoint that doesn't require an API key.
    # It's a great choice for testing the script's functionality.
    PUBLIC_API_URL = "https://jsonplaceholder.typicode.com/posts/1"

    check_api_connection(PUBLIC_API_URL)
</pre>
<pre>
import requests
from requests.exceptions import RequestException
import os
import urllib3

# Disable SSL warnings for unverified HTTPS requests
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def check_api_connection(api_url):
    """
    Checks if a public API endpoint is reachable using a HEAD request.

    :param api_url: The full URL of the public API endpoint to check.
    :return: True if the connection is successful, False otherwise.
    """
    print(f"Attempting to connect to: {api_url}")
    print("-" * 30)

    try:
        # Add verify=False to skip SSL certificate verification
        response = requests.head(api_url, timeout=5, verify=False)

        if 200 <= response.status_code < 300:
            print("✅ Connection successful!")
            print(f"Status Code: {response.status_code}")
            return True
        else:
            print(f"❌ Connection failed. Status Code: {response.status_code}")
            print(f"Reason: {response.reason}")
            return False

    except RequestException as e:
        print(f"❌ An error occurred: {e}")
        return False

# --- Main part of the script ---
if __name__ == "__main__":
    PUBLIC_API_URL = "https://jsonplaceholder.typicode.com/posts/1"
    check_api_connection(PUBLIC_API_URL)
</pre>